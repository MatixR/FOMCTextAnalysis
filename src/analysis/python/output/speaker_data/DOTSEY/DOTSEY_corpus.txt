4  Thanks, Jeff  Mr Chairman and members of the Committee,  our presentation summarizes two important concepts inflation persistence and output  gaps These seemingly disparate concepts are linked through the Phillips curve  We   argue that interpretations  of inflation persistence and output gaps derived from   Phillips curve models are sensitive to assumptions made in estimating these models  and assumptions made about the nature of shocks entering the models   Unfortunately, there is not always a sound basis for choosing among candidate  assumptions  As a result, basing policy discussions on measures of persistence or  output gaps may not be productive   Our work shows that (1) observed inflation persistence may be the result of  monetary policy choices and thus cannot be used to infer structural features of the  economy; (2) statistical measures of output gaps are not useful in formulating  monetary policy; and (3) theoretical measures of output gaps may in principle be  helpful for guiding policy, but in practice they are probably not   Let me turn my attention to my first topic, inflation persistence  To investigate  the potential sources of inflation persistence, we used a simple sticky price model  In  this model, the New Keynesian Phillips curve accounts for deviations of inflation  from average, or trend, inflation  In looking at inflation over the last 50 years, it  appears that inflation can be characterized as a process having a time-varying mean   Thus, how one models trend inflation has important implications for the structure of  the model  If trend inflation is changing over time and is modeled as changing over  time, then the New Keynesian Phillips curve needs to account only for the deviations  of inflation from a changing trend, not for overall inflation  Thus, a New Keynesian  Phillips curve estimated on deviations from trend inflation will predict less backward- looking indexation or shock persistence  There will be fewer structural rigidities than  if the trend is depicted as a constant   To clarify the sources of inflation persistence, consider the reduced-form New  Keynesian Phillips curve on page 3 of the handout  This equation indicates that there  are several potential sources of inflation persistence  Inflation can be persistent  because marginal cost is persistent, because markup shocks are persistent, because  prices are indexed to past inflation, or because the inflation trend is itself persistent   It seems natural to interpret a time-varying inflation trend as the result of a drifting  inflation target    We estimate our simple model for two specifications of the inflation trend, a  specification with a fixed inflation target and a specification with an inflation target  that follows a random walk  We find that allowing for a random walk inflation target  reduces the overall contribution of indexation and markup shocks to inflation  persistence Further, the random walk inflation target specification is statistically  preferred to the constant target specification                          December 15–16, 2009 146 of 247  That finding implies that the persistence of inflation is, to a large degree,  determined by policy  Supporting this point is the observation that historically across  countries inflation persistence depends on the monetary regime  In particular,  inflation persistence is lower in countries that are on a gold standard or where the  central bank targets inflation The finding that inflation persistence is largely  determined by monetary policy and that other sources of persistence are not very  important implies that policy is fully capable of changing the behavior of inflation  without generating large economic costs, especially if inflation expectations are well  anchored   Now let me turn to my second topic, the usefulness of output gaps for conducting  monetary policy We are going to conclude that they are not very useful  Broadly  speaking, output gaps refer to the deviation of output from a level deemed to be  desirable Thus, constructing an output gap requires one to take a stand on the  desired level of output, often referred to as potential output  There are two primary  approaches to defining and measuring potential output  those based on statistical  procedures and those based on explicit theoretical models  Statistical measures of  potential output are constructed either as smoothed measures of actual output or  smoothed estimates of output derived from a production function   A second approach to constructing potential output relies on estimated theoretical  models, where the behaviors of output and potential output depend on the structure of  the economy and the exogenous shocks buffeting the economy  Some features of the  economy’s structure and some of the shocks hitting the economy may give rise to  inefficient outcomes  For example, monopolistic price setting and nominal rigidities  introduce distortions In addition, markup shocks introduce inefficient fluctuations   This suggests defining potential output as that output that could be obtained in the  absence of distortions and inefficient shocks, but including the effects of shocks that  are classified as efficient  In simple versions of these models, a monetary policy that  minimizes the difference between actual output and the model-based definition of  potential output, that is, the model-based output gap, is welfare improving   Thus, in principle, model-based output gaps may be useful for policy purposes  In  contrast, the statistical measures of the output gap are less useful for policy purposes,  because these measures need not be closely related to model-based gaps  For  example, in figure 1 of the handout we consider a productivity increase in an  economy with sticky nominal prices  With sticky prices, output responds more  sluggishly than it would if prices were flexible  Because of this, potential output rises  by more than actual output, and the theoretical output gap is negative  However, if  we were to graph a statistical measure of potential, which is a smoothed version of  actual output, it would rise by less than actual output, producing a positive output  gap Thus the model-based output gap and the statistical-based output gap would  move in opposite directions and imply different monetary policy responses  This  example illustrates why we think it unwise to base policy on statistical-based gaps                                 December 15–16, 2009 147 of 247  However, at this stage of model development, we are also uncomfortable with  using model-based gaps for policy purposes  First, in more complicated models, the  output gap is no longer a sufficient statistic for evaluating the welfare implications of  monetary policy Moreover, the models are still preliminary  In addition, shocks  play an important quantitative role in these models, but the economic interpretation of  many of these shocks is unclear   While we have come to accept productivity shocks as structural, we have not yet  reached that comfort level with many of the new “structural” shocks coming out of  New Keynesian Phillips curve models   It is also of importance that different models may produce very different measures  of the output gap In figure 2 we plot the output gaps from three representative  models The blue line represents the output gap from our small-scale model, the  green line is the output gap from a medium-scale New Keynesian Phillips curve  model developed by my colleague Keith Sill, and the two red lines represent  alternative output gaps from the Board’s larger-scale EDO model  It is abundantly  clear that the output gaps from these different models are very different  We,  therefore, are not confident that, given the current state of knowledge, one can rely on  model-based gaps as sufficient indicators for monetary policy   On a more positive note, we believe that the process of formulating and  estimating a particular model can be quite useful for policy purposes  Estimation can  inform a policymaker about the shocks that the model suggests are impacting the  economy  If the shocks have been correctly identified, the model can be a useful  guide to policy A general lesson from our models is that it is not enough to know  that output is high or low relative to trend to conclude that output is high or low  relative to potential; rather one needs to know something about the shocks hitting the  economy and the assumed structure of the economy  It seems more appropriate that  policy discussions should proceed based on explicit discussion of these shocks, rather  than the implied gaps   From this we conclude that the use of models in policy discussions is beneficial   Also, because we have no agreed-upon model, it is useful to consider the implications  from a number of models, and it is certainly not necessary that all the models be of  the New Keynesian variety It is only the careful consideration of a full range of  imperfect models that enlightens and places discipline on policy discussions   In that regard, the Chicago exercise falls into the class of exercises that we find  productive They provide a detailed exposition of their model, the various variables  constructed using their model, and the contribution of shocks to these constructs   This is consistent with the way we suggest policy discussions be conducted  We are,  however, more skeptical of the specifics of their exercise  They find that their  measure of potential output, which conforms to our definition of potential, helps  explain another model construct that they call “fundamental inflation”  We don’t  think this is much of a surprise  Fundamental inflation is the part of detrended                                                                    5 The materials used by Mr Wynne are appended to this transcript (appendix 5)   December 15–16, 2009 148 of 247  inflation generated by efficient shocks in their model absent inefficiencies and is thus  constructed similarly to the way they construct potential output  That strategy  increases the chance that those two constructs will be correlated  However, this  correlation is not necessarily useful for policy purposes  In particular, fundamental  inflation is only weakly correlated with actual inflation, implying that their model,  like most models, doesn’t provide a good structural explanation of inflation   Therefore, from an academic perspective, their results are very interesting, but from a  policy perspective less so, because knowing the Chicago measure of potential output  tells us very little about actual inflation  This is a key point of the Philadelphia- Richmond presentation  And now I’ll turn it over to Mark    I really can’t answer that I haven’t done that research, and I haven’t   looked into that I don’t know if Andreas, who’s also with me today, has anything he could add    I don’t know if I can tell you exactly what’s going on in the economy   today That’s a little bit of a hard road to walk down  But with regard to your first point, if I   were sitting at this table, I would find the discussion among Charlie and Narayana and Jeff very   productive Charlie could have had his entire discussion without mentioning the word “gap”   once Basically he was talking about what kind of shocks he thinks are hitting the economy,   given an underlying model based on, I guess, some of his own work and things like that  What     December 15–16, 2009 169 of 247  kind of impact would those shocks have on the economy, and then what should monetary   policy’s actual response be?  That I find extremely valuable in my own thinking, and that’s the   way I think about policy   The gap construct is something that, as Charlie commented, is going to be model-   specific But I find that when people rely on that too much without doing the hard work, which   people have done around here in this discussion, of talking about what are the beneficial models   that help us understand things and the disagreements we might have over them in terms of   identifying what’s going on, then that can sometimes lead away from a productive discussion    So I don’t know what you talked about this morning, but if you—    It’s unfortunate for the New Keynesian models that at this point it seems   that what we had was a large financial meltdown  What we do not have yet, but which is part of   the big research agenda that’s just taking off, is a way to integrate the way we think about   financial markets and their role in the economy  So if I were trying to do things now, I might say   I’m going to go look at Bernanke and Gertler and Gilchrist or I’m going to look at Kiyotake and   Moore or maybe models like Diamond and Rajan and I might even pull away from the New   Keynesian paradigm and try to understand what they’re telling us is going on in the economy,   and then try to figure out a response So I think there’s no getting around it, as Jeff Lacker   says—we’ve got to put our models on the table, see where they fit things, and then figure stuff   out imperfectly  And in that discussion, if you want to use gaps and you find them helpful, that’s   fine, and they may be a good communication device as well  But I don’t think they’re essential    They’re an artificially constructed device that you can just sort of think about or not           December 15–16, 2009 170 of 247   I would be no more informative on that than anybody here  But one   could say that one of the things that has happened in financial markets is that capital is not being   allocated efficiently across the economy; that is, the firms that might be getting the capital in   normal times, maybe smaller productive firms, are not getting it, and some larger, non­  productive firms, perhaps because they have better balance sheets or have been around, are   getting it, and that would look like a technology shock   But, then again, maybe we’re in a world where we have ambiguity aversion in our model,   and all of a sudden people have become very, very uncertain about things or demanding large   risk premiums, and, as a result, investment isn’t being done because it’s being priced in a crazy   way    In the Philadelphia model where this is being soaked up as an inefficient   investment shock that tells you that potential is going down a lot as well as output    I’m a little bit uncomfortable with that as the explanation, but that’s   what that particular New Keynesian model would say  I’m trying to remember, I think the model            December 15–16, 2009 171 of 247  at Chicago also has a big role for some of these investment-type technology shocks as well and   whether they are—     Given that unemployment has gone up to 10 percent, and in Jeff’s   graphs you thought that we had this 8 percent drop in marginal cost, or some giant gap, the   question would be Why hasn’t inflation gone from 22 percent to minus 22 percent, not from    22 percent to 1½ percent?    That’s a really excellent question, which I’m going to answer in three   parts In the models that we’re all looking at, expectations are rational  To the extent that that’s   not a good approximation for how people actually form expectations, then that’s problematic for   the models as well  People like Jim Bullard have worked on models of learning and other types        December 15–16, 2009 180 of 247  of things, and a lot of those models probably can be incorporated to try to flesh out expectational   issues, if we become uncomfortable with the assumption of rational expectations at high   frequencies   Expectations are a dicey thing for the Committee to base policy on, because often they   can be somewhat sticky, as you allude to  If the Committee were to lose some of its credibility,   often those expectations could look good, but you could have lost the game, and expectations are   going to get out of hand I think the late 1970s and then the disinflation of the 1980s was an   example of that  The inflation sort of led the expectations—we had this big run-up in inflation,   and expectations followed it On the way down, I think expectations of inflation actually   followed the Fed’s moves as it was gaining credibility and probably made the disinflationary   costs in actuality a lot worse  So I think you are right to point out those types of things, but,   again, all I can do is say we’ve got these models on the table, and that’s the best we can do  And   you’re right to question perhaps some of the assumptions underlying what is going on   1  Mr Chairman and FOMC participants, good morning, and  thank you for giving me the opportunity to introduce the System’s DSGE project to  you  First, I would like to give you a brief overview of dynamic stochastic general  equilibrium, or DSGE, models and indicate how they can provide useful input into  the policy process  Then I will illustrate two uses of the models  their ability to  identify economic disturbances that are responsible for a given event—in our case,  the Great Recession—and their use as a forecasting tool  In my discussion, I will  concentrate on the relative strengths of the methodology, but I will also make you  aware of the pitfalls  I will conclude by describing other uses of the models that the  FOMC might be interested in   Let me begin by reviewing the methodology employed in DSGE models   Specifically, what are DSGE models, what makes them special, what are their  strengths and weaknesses, and how should they be used in conjunction with the other  tools available to policymakers?   As summarized in exhibit 1, DSGE models are small to medium-sized economic  models  Thus, they are much smaller than FRB/US but generally larger than simple  time-series models such as vector autoregressions  Notably, DSGE models are also                                                     1 The materials used by Mr Dotsey are appended to this transcript (appendix 1)   June 21–22, 2011 5 of 282              structural in nature, meaning that they specify the objectives and constraints of each  decisionmaker in the model  This feature implies that the shocks in the models can be  given an economic interpretation, and that the models can be used to analyze policy  changes  The decisionmakers in the models include a private sector composed of  households and firms, as well as a public sector made up of a fiscal authority and a  central bank  The private agents in the model solve explicit optimization problems,  and expectations of future economic conditions are central determinants of their  behavior  A distinguishing feature of the DSGE methodology is that these  expectations of future economic conditions are endogenous  This means that  households and firms incorporate expectations of future policy into their current  decisions  This is an especially important feature when examining the effects of  alternative policies or discussing the effects of anticipated policy changes   As their name implies, DSGE models are general-equilibrium models, implying  that prices, interest rates, and wages adjust so that supply equals demand in all  markets at any given point in time  In addition, the models are stochastic, and  economic fluctuations are generated by shocks  For example, changes in  productivity, unanticipated changes in monetary policy, and changes in the efficiency  of financial intermediation are factors that influence the behavior of the model  economies  The shocks capture the inherent unpredictability of macroeconomic data   The parameters of the model are usually estimated using Bayesian statistical  techniques  The statistical methodology allows the user to characterize the  uncertainty surrounding the parameter estimates and the economic forecasts that are  produced by the model, as well as the uncertainty surrounding the results of  alternative policy experiments    DSGE models have become an extensive research topic at many central banks  because the use of an explicit optimizing model makes the output of DSGE models— whether that output is an economic forecast, the results of a policy experiment, or the  analysis of the sources of economic fluctuations—readily interpretable in terms of  economic theory  Thus, DSGE models can address a host of issues that are relevant  to policymakers   Let me now go into a bit more depth concerning the basic building blocks of the  models, which are summarized in exhibit 2 in the handout  First, the models have a  production side  Firms employ workers and rent capital in order to produce goods,  and production is subject to productivity shocks  Firms also have pricing power, and  prices adjust slowly  These price rigidities are an important feature of the models and  an important element in aligning the models with the data  The pricing mechanism  generates a Phillips curve that relates inflation to a measure of economic activity   Along with productivity shocks, firms’ decisions are directly influenced by shocks to  the markup of price over marginal cost   The second major participants in the model are households  They own the firms  and the capital stock either directly or indirectly through their ownership of financial  intermediaries  They choose how much to consume and save as well as how much   June 21–22, 2011 6 of 282              labor to supply  As with prices, wages are not fully flexible  They adjust slowly in  response to economic disturbances   A third component of some but not all of our models is a financial intermediation  sector  For those that don’t, one may interpret the investment process as involving  some form of indirect financial intermediation that transforms savings into additional  capital, and this transformation is costly  These costs affect the productivity of  investment  As shown in a 2011 paper by Justiniano, Primiceri, and Tambalotti,  changes in the efficiency of investment may be given a financial interpretation  Other  disturbances that influence households’ decisions are shocks to the rate of time  discount (how impatient the household is) and shocks to labor supply  Shocks to the  rate of time discount influence how a household allocates resources between  consumption and saving and so are important in generating differential growth  patterns in consumption and investment  Shocks to labor supply are intended to  capture labor market frictions beyond those involving wage rigidity   Most of the models also involve nonproductive consumption by the government,  but that is generally the extent to which fiscal policy is incorporated into the model   Shocks to government spending are basically shocks to the economy’s overall  resource constraint and can, therefore, also be interpreted as shocks to net exports   Monetary policy is captured by a generalized Taylor rule, with interest rates  responding to inflation relative to target and some measure of economic activity  Interest rates adjust gradually, and monetary policy shocks capture deviations of the  interest rate from this rule  The parameters of the rule are estimated and, therefore,  based on the past behavior of policy   Model development is ongoing, and although the models employed by the various  Reserve Banks and the Board share most of the above features, they do differ along a  number of dimensions  The Philadelphia Fed is closest to the basic structure just  outlined  The New York model incorporates a specific financial sector along the lines  of Bernanke, Gertler, and Gilchrist (1999), and the Board EDO model has multiple  sectors and incorporates risk premiums into the pricing of bonds  The Chicago model  includes technical progress driven by improvements in the productivity of capital and  uses an interest rate spread to identify changes in the efficiency of investment  It also  incorporates multiple measures of inflation to estimate its common persistent  component  Consequently, the project includes a rich set of DSGE models that  unsurprisingly sometimes present different interpretations of economic events   We view this diversity as a strength of our project  Using a number of different  DSGE models allows us to ascertain, to some degree, the extent of model uncertainty  along with the uncertainty that characterizes each particular model  Examining model  uncertainty is an important part of analyzing the output of DSGE exercises, because  economists are in general more uncertain about their models than they are regarding  the parameter values of any particular model  As well, quantifying the degree of  uncertainty surrounding any particular exercise is informative for policymakers, as it   June 21–22, 2011 7 of 282              establishes the degree of confidence that can be associated with the predictions of the  models and how various model specifications influence those predictions   Having described the general structure of the DSGE models used in our project, I  will now turn to some of their uses  These are summarized in exhibit 3  First, the  models can be used to forecast the variables included in the models but may also be  used to forecast nonmodel variables as well  That exercise has been performed with  the Philadelphia model  The forecasts are generally of a quality similar to reduced- form forecasts and forecasts that are more judgmental in nature  The models are also  amenable to “nowcasting” exercises, which incorporate more timely current-quarter  information  The forecasts I will present in this briefing are nowcasts   Second, DSGE models allow us to identify the disturbances that are driving  economic fluctuations and the forecast, as well as understand how these disturbances  affect economic activity  This strength of the DSGE framework is what is shown in  the analysis of the Great Recession that I will present in a moment  As a preview, we  find that the models in our project identify those shocks that are most closely linked  with financial intermediation as responsible for the recent recession   Third, DSGE models can be used to explore the effects of alternative policies   The estimation focuses on parameters that are assumed to be invariant to policy  changes  Consequently, we can analyze the effects of policy changes using the  estimated parameters of the model   My overview would be incomplete if I did not point out some of the inherent  limitations of the DSGE approach  It is important to note that many of these  weaknesses are generic and not particular to DSGE models  One weakness is that the  models are not large in scale, which may result in some economic variables that are of  interest being overlooked  Further, as is true of all economic models, DSGE models  represent approximations and are, therefore, subject to model misspecification  Also,  all of the models I discuss ignore open economy aspects, firms’ and households’  heterogeneity, and several other features that are potentially important for the  transmission mechanism of various shocks  However, the importance of the  misspecification can be tested by comparing the fit of the DSGE model with that of  more heavily parameterized reduced-form models   Another consideration is that some of the behavioral relationships may not be  invariant to policy interventions  The DSGE approach aims to minimize this  problem, but it is not altogether immune from it  For example, the way firms set  prices in the model is not fully based on optimizing behavior, and the estimated  parameters that govern price setting are probably not invariant to alternative policies   Also, the labor supply decisions in the models may not correspond very well to actual  labor market behavior  Incorporating more realistic models of the labor market is part  of an ongoing research effort in the DSGE model-building community  Finally, the  models often lack important sectors, such as a sophisticated financial sector, and the  modeling of fiscal policy is quite simplistic   June 21–22, 2011 8 of 282              That said, we believe that these weaknesses are more than offset by the strengths  of the DSGE framework and these models should be an important element of a  policymaker’s toolkit  They can be used to interpret economic fluctuations and serve  as a complement to other forecasting methodologies that policymakers currently rely  on  Importantly, the models provide an internally consistent way of carrying out the  analysis of alternative policies  As an example, they could be used to analyze the  differences between unanticipated changes to policy as opposed to anticipated ones   DSGE models are increasingly being used by other central banks to inform monetary  policy, and we believe they can be put to effective use by the FOMC   Let me now focus on the first of our two exercises—namely, analyzing the causes  of the Great Recession  This episode is particularly important both because of its  severity and because it plays an important role in the current forecasts  Explaining  the Great Recession is especially challenging for our project because only two of our  models explicitly incorporate financial variables, and only the New York  model does  so endogenously  Nevertheless, the models reach some similar conclusions   Exhibit 4 of your handout displays some of the key variables used in estimating  the various models  Examining the broad contours of the data indicates that the  recession was quite deep, especially regarding investment and hours worked  Real  GDP in the second quarter of 2009 was more than 4 percent below its level of a year  earlier, the sharpest four-quarter decline since the Great Depression  The decline in  business fixed investment was even more severe, falling nearly 21 percent over the  same period  Commensurately, hours worked in the nonfarm business sector fell  8 percent and payroll employment fell nearly 5 percent  Inflation fell during the  recession, but the decline was not dramatic  Notably, the huge run-up in interest rate  spreads provides evidence of severe financial distress   My discussion of the Great Recession will tie together the common features  characterizing the individual models’ explanation of the recession  I will also point  out a few differences among the models’ identifications regarding the main factors  that contributed to the crisis  More detailed descriptions of how each model  interpreted the recession are contained in the briefing material that was circulated  before the meeting  In explaining the shocks that drove the Great Recession, whether  a model explicitly incorporates a financial sector and financial variables is of prime  importance  Of the four models, the New York model and the Board’s EDO model  explicitly incorporate the effects of financial distress  In the New York model,  financial frictions generate a wedge between the interest rate paid by investors and  the interest rate on government securities, and in the EDO model, the financial  distress is directly associated with shocks to various risk premiums  Thus, a key  driver in the New York model’s explanation of the recession is a widening of the  spread due to an increase in the riskiness of borrowers  This shock is identified by  the behavior of the Baa corporate bond rate over the rate on 10-year Treasuries   These financial shocks help the model capture a good deal of what actually occurred  in the early part of the recession because they impair the allocation of funds to  investment projects, reducing investment, output, and hours, and causing inflation to  decline  The effect is also amplified by the stickiness of prices and wages in the   June 21–22, 2011 9 of 282              model  Similarly, EDO identified shocks to risk premiums as important drivers of the  recession, and the identification of risk premiums shocks allowed the model to  capture the collapse in investment-type expenditures   Neither the Chicago nor the Philadelphia model explicitly includes a financial  intermediation sector  Nevertheless, the shocks that contribute the most to their  explanation of the recession are those closely tied to the transformation of savings  into investment  In particular, negative shocks to the efficiency of investment  contribute substantially to the fall in investment and output  A negative shock to the  efficiency of investment literally implies that a unit of investment produces less  capital than it normally would, making investing less desirable  More broadly, these  reflect deterioration in the efficiency of financial intermediation  As financial  markets recovered during the recession, this shock also played a key role in the New  York model’s explanation of the prolonged economic weakness  It is also the case  that a decline in the value consumers attached to current consumption relative to  future consumption—a shock to consumers’ discount rate—reduced output and  interest rates in both the Chicago and the Philadelphia models  Both shocks also  imply a decline in inflation because they reduce aggregate demand   Let me now turn to our final exercise, which involves a current forecast of the  economy  The forecasts are summarized in exhibit 5  These are updated from the  ones you initially received in the main document and were included in the  subsequently circulated addendum  The new forecasts are conditioned on  second-quarter economic data and are displayed in exhibits 6 through 8  Because the  models differ along a number of dimensions, their forecasts provide different lenses  for viewing the economy   Regarding output growth, which is shown in exhibit 6, all four models depict an  economy in recovery, with a median forecasted growth rate of 29 percent in 2011  and 35 percent in 2012  The four models differ markedly regarding the strength of  the recovery, however  The Philadelphia and Chicago models anticipate robust  recoveries; the Board’s model predicts real economic growth roughly in line with  trend (about 27 percent), while the New York model predicts growth slightly below  trend  The main differences across the model forecasts can be traced to whether the  shocks that generated the recession continue to hinder the return of output to  potential, or whether they dissipate, allowing a rapid rebound in economic activity   The Philadelphia and Chicago models, and to a lesser extent the Board’s EDO model,  represent the latter case  As the economy returns to its potential after the strain from  “financial” shocks, these models forecast relatively sustained growth  The New York  model represents the other extreme  In that model, the headwinds from the financial  crisis have an adverse effect on economic activity for a very prolonged period, and  hence the recovery is subdued   As shown in exhibit 7, the inflation forecasts display more agreement across  models  For the most part, the models indicate downward pressure on core inflation  in response to weak aggregate demand and a level of economic activity below  potential through the end of the forecast horizon  The New York, EDO, and   June 21–22, 2011 10 of 282              Philadelphia models anticipate that inflation will be in the 13 percent to 15 percent  range by the end of 2013, while the Chicago model expects a sharp decline in  inflation  Taken together, the models do not anticipate significant inflationary  pressures over the forecast horizon  For the most part, the recent surge in inflation is  viewed as transitory and hence does not call for a large policy response in the  forecasts   Turning to exhibit 8, the interest rate forecasts of the models imply somewhat  different paths for monetary policy  The paths differ because the models differ in  their forecasts for output and inflation, and they specify different monetary policy  rules  In the Philadelphia model and the Board’s EDO model, monetary policy reacts  to a longer-run measure of output, and it reacts to the four-quarter growth in output in  the Chicago and New York models  The New York, Chicago, and Philadelphia  models impose an “extended period” of zero interest rates until mid-2012  All project  a modest tightening thereafter because they expect inflation to remain below target   This forecast is similar to the EDO model’s forecast, which anticipates that tightening  will begin in late 2011  By the end of 2012, the federal funds rate is expected to  reach 09 percent in the New York model, 10 percent in the Chicago model,  06 percent in the Philadelphia model, and 16 percent in EDO  Thereafter, policy is  expected to tighten at a modest-to-measured pace   Having reviewed the basic methodology of DSGE models and presented two of  their uses, I would like to conclude by summarizing their main strengths and by  suggesting a few ways in which the FOMC may wish to use our DSGE model project   Two distinguishing features of the DSGE methodology are the endogenous nature of  expectations and forward-looking optimizing behavior  Incorporating these two  elements is crucial for analyzing the effects of alternative policies and for making the  output of the models interpretable in terms of modern macroeconomic theory   Further, the diverse nature of the models in the project allows us to characterize the  inherent uncertainty surrounding any of our exercises   One goal of the DSGE project is to provide additional forecasting exercises that  the Committee will see as useful complements to other forecasts already used by the  Committee  In future work, we plan to investigate in more depth the properties of our  forecasts and can potentially combine the information in the various forecasts to  produce an improved single forecast  To that end, we can explore more formally the  forecasting accuracy of the individual models as well as average forecasts of the  models in our project, and compare our forecasts with those of other models and  surveys  This would give the Committee another well-documented forecasting tool  Additionally, we believe that the models can help the Committee identify the types of  disturbances that are most likely affecting the economy  This knowledge can aid  policymakers’ decisions, as the appropriate response to productivity-induced  economic growth may be different from growth originating from demand  disturbances  Importantly, the models can be used to ascertain the effects of  alternative policies, whether they be slight departures from normal operating  procedures or more significant changes in how monetary policy is carried out  We  would be happy to answer any questions you have about this project   June 21–22, 2011 11 of 282                I agree with you on these things  Right now, the models that we have   mix extensive and intensive margins, and we really don’t talk about things like unemployment    It is true that deviations of where the model is from a steady state are very important, and those   are gap-like concepts, but not exactly what you may be asking about  A lot of those types of   things, though, are on the DSGE framework  I think that many of the things you suggest are   doable; they just haven’t been done yet  They involve a lot of work, and researchers have to   figure out which ones they want to attack and in what order  As I mentioned in my briefing,   developing more realistic labor market sectors, where we can actually look at unemployment   measures in more detail, are certainly front and center  None of our models incorporates that   June 21–22, 2011 12 of 282                Okay  With regard to forecasting, there has been only a little bit of work   done with these particular models formally testing how well they forecast  In particular, the   EDO model has done some exercises, I believe, over the 1997 to 2004 period, and I think the   answer is that it does about as well as FRB/US   Some other work that I have read by somebody at the ECB has looked at three or four   different DSGE models—the Smets-Wouters model, something very close to EDO—and has   looked at model averaging  In those particular exercises, when you start looking three and four   and five quarters out, the DSGE approach seems to outforecast what was in the Greenbook when   it comes to output growth, does slightly less well on inflation, and actually, surprisingly, does a   little bit better at predicting the Committee’s own behavior three, four, and five quarters out    These are not our models, and certainly, if you were to use the forecasts from our models, I agree   June 21–22, 2011 13 of 282              that one of the things that we need to be able to bring to your attention is how well their forecasts   have done over a period of time in comparison with others   In terms of trying to think about misspecification—and I’m going to let some of my   colleagues pipe in, if they want to, because they are the actual experts on model development    When you start seeing really, really huge shocks that have to drive everything and the shocks   take on a very persistent type of character, then you can be somewhat skeptical of the model    That is a signal that something outside the model that is driving things  Then you may have to   say, “Well, maybe in this particular case, because it is just large persistent shocks and is not   something endogenous to the model, we are not looking at your DSGE model today”   In terms of credit standards, I believe in the New York model—I’m going to let Marco   answer this in a minute—those types of things reflect, for example, how much net worth people   have and how risky the borrowers are, and that will influence credit spreads endogenously  In   the EDO model, the risk premium is, as you say, exogenous  But there are models on the shelf   that do look at these net worth characteristics and how they do affect credit spreads, and I believe   that those could be incorporated into the framework as we go forward  I would like to turn to   Marco, who has done more work on this, if that’s okay     I am not an expert on FRB/US, so I don’t think I can really say exactly   what the weaknesses are of FRB/US versus the DSGE framework  What I can say is what you   alluded to—that the DSGE framework, because of its manageable size and the restrictions   associated with forward-looking and optimizing behavior, allows us to, as you said, characterize   the shocks  We can look at impulse-response functions that we know are related to a   June 21–22, 2011 16 of 282              fundamental type of shock, rather than something that may be just a reduced-form forecast error,   and see how that plays through the economy, giving people an idea of how the model works   In regard to gaps, there are numerous ways to construct gaps  The models themselves   don’t find most of those constructions as a first-order part of the model  So basically, the gaps   that most of us can tell you about are where we are relative to the steady-state growth of the   economy  And most of these models were a long way away, between 4 and 10 percent    Regarding the New York Fed model, I’ll let Marco field the question     First, we don’t have a rich term structure or any type of market   segmentation in the asset market  So with regard to QE2, that’s not going to be done directly    June 21–22, 2011 18 of 282              But there are other studies that we can piggyback on that indicate how much so many hundred   billions of dollars of assets move down the 10-year Treasury rate, or whatever maturity you are   doing  And then there are other studies that translate that into a funds rate–type of decision    Putting it in terms of the funds rate, and perhaps relaxing the zero lower bound constraint would   be a way that these models could, in an indirect way, handle that  QE1 seems different, and that   is handled directly in the New York model because when QE1 came along, a lot of spreads went   down quite rapidly  And those do directly affect what is going on in the New York and Chicago   models  For Philadelphia, in the Prism model, it’s going to affect what kind of marginal   efficiency of investment shocks we are going to be seeing  But I regard QE1 and QE2 as two   different policies that the models would incorporate in two different ways     I agree with part of it, and I disagree with part of it  I agree with you   that forecasting should not be the only emphasis on these models  These are small models that   are tightly parameterized  I don’t share Mike Kiley’s view that the glass is half empty  I say,   “The glass is half full,” and that these models, as tightly parameterized as they are, and not   taking account of all the additional degrees of freedom that the big models have, are doing about   as well  However, if they were forecasting so abominably that we thought that they had no   attachment with reality, then we might want to step back and ask, “Do we really want to use   these models for any of the other things they are designed to do?”  The fact that they are   forecasting about as well as reduced form models, which is pretty good, suggests that they are in   an area where they can do the types of experiments you want and be informative as well   So I agree with the general thrust of what you are saying, but I think forecasting still is   somewhat important  I think the Committee would not want to pay attention to models that   couldn’t forecast at all  For instance, if we did the Great Recession exercise, and we all found   out that technology shocks were driving the entire Great Recession, you might ask, “Well, why   would I want to look at these models for analyzing anything that looked like a banking crisis in   any detail?”  But we didn’t find that, so that’s reassuring     I think that’s very similar to what Governor Yellen alluded to in terms of   robustness  Certainly, measurement error can be introduced into these models, and then robust   rules in the style that John Williams’s research has explored over a number of years can be   undertaken, given the kinds of uncertainty we might have about measuring a gap or even what   conceptually we think a gap is  I think these models can certainly deal with what kind of rules   would be most beneficial under those types of uncertainty  A lot of John’s work was in a linear   rational expectations environment and some of it was in a learning environment, and both of   those types of environments are amenable to the scale of models that we have on the table     I agree exactly with David  I won’t reiterate  You eloquently, probably   more than I, indicated what some of the strengths of these models are, but I think that they are   still a bit too small  For example, fiscal policies are problematic; these models don’t have   distortionary taxation and details along those lines  We’re also building better financial   intermediation sectors, which are really important, and there may be a few other things  Do we   June 21–22, 2011 26 of 282              have to go to the level of a chemical industry?  Probably not, and we would lose the transparency   that these models can give that’s so important  But like Dave just indicated, I think the group   involved in the project views our work as complementary work for the Committee; these models   have certain strengths, and we’d like to make them available to the Committee  And you have   other models that have other strengths, and like you’re saying, you should be looking at more   than one thing because we don’t have the model of the United States economy or the world   economy  